{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Question: What is LangChain, and how can it be used in the field of natural language processing (NLP)?\\n\\n\\nLangChain appears to be a hypothetical tool or framework designed for working with large language models within the realm of NLP tasks. While I must note that as of my last update there isn't an established LangChain specifically, it is conceivable how such a system could function if we break down its components and purposes:\\n\\n1. Interface Design - A user-friendly interface for developers to interact with language models without requiring extensive coding knowledge, possibly leveraging Python or JavaScript due to their popularity in the NLP community. \\n\\n2. Preprocessing Utilities - Functions that cleanse input data (text) by removing noise such as special characters and stop words which could otherwise interfere with model performance on certain tasks like text generation or sentiment analysis. This pre-cleaned text is then tokenized into chunks suitable for the chosen language models to process efficiently, without overloading system memory resources that may be limited in some contexts (e.g., embedded devices).\\n\\n3. Postprocessing Utilities - Functions designed to refine outputs from large NLP systems by applying techniques like beam search or sampling with temperature adjustments and controlling diversity through repetition thresholds, enabling the generation of varied and coherent text responses in applications such as chatbots or content creation tools.\\n\\n4. Data Loading - Capabilities for seamless loading data into language models using formats like JSON Lines (jsonl) which can facilitate scalable model training on large datasets with minimal latency, supporting tasks that require extensive and diverse input corpus such as multilingual text understanding or complex dialogue systems development.\\n\\n5. Fine-tuning & Transfer Learning - A module allowing users to fine-tune pre-trained language models using a subset of their own task-specific data for enhanced performance on particular NLP problems, with guidance provided through clear instructions and minimal technical barriers within the LangChain environment itself. This might include features like prompt engineering or customized training loops tailored to specific applications (e.g., extracting information from legal documents).\\n\\n6. Model Evaluation - Incorporating tools for assessing model performance on various NLP tasks, which could involve metrics and visualizations such as BLEU scores for translation quality evaluation or perplexity calculations during text generation processes to monitor improvements iteratively throughout the development cycle in a transparent manner accessible by developers without specialized expertise.\\n\\n7. Integration with Pre-trained Models - The ability of LangChain to connect smoothly and flexibly with widely recognized pre-trained language models like GPT-3 or BERT, along with support for newer model architectures that may emerge in the future as they advance within the NLP research community.\\n\\n8. Community & Resources Sharing - A platform where developers can share insights on best practices and strategies to effectively leverage these large language models (LLMs) across different applications, perhaps including a forum or collaborative repository for code snippets, tutorials, case studies, and performance benchmarking results that foster collective growth within the NLP community.\\n\\n\\nThis conceptual LangChain could serve as an accessible bridge between complex underlying technology of large language models (LLMs) such as GPT-3 or similar systems like Google's PaLM or Microsoft’s Phi and end users with a variety of tasks in natural language understanding, generation, summarization, translation, etc. By simplifying access to advanced NLP capabilities without compromising on the quality of results obtained from these powerful models, it has the potential to empower businesses, developers, researchers as well as hobbyists alike with practical tools for real-world applications while promoting further innovation and experimentation in the field.\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_ollama.llms import OllamaLLM\n",
    "\n",
    "template = \"\"\"Question: {question}\n",
    "\n",
    "Answer: Let's think step by step.\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "model = OllamaLLM(model=\"phi3\")\n",
    "\n",
    "chain = prompt | model\n",
    "\n",
    "chain.invoke({\"question\": \"What is LangChain?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import WebBaseLoader\n",
    "loader = WebBaseLoader(\"https://www.gutenberg.org/files/1727/1727-h/1727-h.htm\")\n",
    "data = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter=RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=20)\n",
    "all_splits = text_splitter.split_documents(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import OllamaEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "oembed = OllamaEmbeddings(base_url=\"http://localhost:11434\", model=\"nomic-embed-text\")\n",
    "vectorstore = Chroma.from_documents(documents=all_splits, embedding=oembed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "[Document(metadata={'language': 'en', 'source': 'https://www.gutenberg.org/files/1727/1727-h/1727-h.htm', 'title': 'The Project Gutenberg eBook of The Odyssey, by Homer'}, page_content='Thoon, Anabesineus, and Amphialus son of Polyneus son of Tecton. There was also\\r\\nEuryalus son of Naubolus, who was like Mars himself, and was the best looking\\r\\nman among the Phaeacians except Laodamas. Three sons of Alcinous, Laodamas,\\r\\nHalios, and Clytoneus, competed also.'), Document(metadata={'language': 'en', 'source': 'https://www.gutenberg.org/files/1727/1727-h/1727-h.htm', 'title': 'The Project Gutenberg eBook of The Odyssey, by Homer'}, page_content='Thoon, Anabesineus, and Amphialus son of Polyneus son of Tecton. There was also\\r\\nEuryalus son of Naubolus, who was like Mars himself, and was the best looking\\r\\nman among the Phaeacians except Laodamas. Three sons of Alcinous, Laodamas,\\r\\nHalios, and Clytoneus, competed also.'), Document(metadata={'language': 'en', 'source': 'https://www.gutenberg.org/files/1727/1727-h/1727-h.htm', 'title': 'The Project Gutenberg eBook of The Odyssey, by Homer'}, page_content='“This is the house, father stranger, which you would have me show you. You will\\r\\nfind a number of great people sitting at table, but do not be afraid; go\\r\\nstraight in, for the bolder a man is the more likely he is to carry his point,\\r\\neven though he is a stranger. First find the queen. Her name is Arete, and she\\r\\ncomes of the same family as her husband Alcinous. They both descend originally\\r\\nfrom Neptune, who was father to Nausithous by Periboea, a woman of great'), Document(metadata={'language': 'en', 'source': 'https://www.gutenberg.org/files/1727/1727-h/1727-h.htm', 'title': 'The Project Gutenberg eBook of The Odyssey, by Homer'}, page_content='“This is the house, father stranger, which you would have me show you. You will\\r\\nfind a number of great people sitting at table, but do not be afraid; go\\r\\nstraight in, for the bolder a man is the more likely he is to carry his point,\\r\\neven though he is a stranger. First find the queen. Her name is Arete, and she\\r\\ncomes of the same family as her husband Alcinous. They both descend originally\\r\\nfrom Neptune, who was father to Nausithous by Periboea, a woman of great')]\n"
     ]
    }
   ],
   "source": [
    "question=\"Who is Neleus and who is in Neleus' family?\"\n",
    "docs = vectorstore.similarity_search(question)\n",
    "print(len(docs))\n",
    "print(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neleus is not mentioned directly within the provided context. However, it can be inferred that he could potentially belong to Alcinous’ extended family as his father was Nausithous, whose lineage traces back to Neptune and Periboea (who descended from Oceanid Melpomene), thereby making Neleus a relative of the Phaeacian royalty. However, without explicit mention or direct information about Neleus in this context, it is impossible for me to provide specific details on his family members aside from Alcinous and Nausithous.\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
